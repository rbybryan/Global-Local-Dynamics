{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_visualize_filters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCGC6eltjici"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqjzHpn3e3_b"
      },
      "source": [
        "%cd /content/drive/MyDrive/subfolder/Global_local"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go1YiIYRe24k"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import h5py\n",
        "import imutils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch import autograd\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-zLolnqGxM8"
      },
      "source": [
        "#define customized model\n",
        "\n",
        "cls = 9\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch), \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, input):\n",
        "        return self.conv(input)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, 16, 7, stride=2, padding = 4)  #224\n",
        "        self.pool0 = nn.MaxPool2d(3,2)\n",
        "        self.conv1 = DoubleConv(16, 32)  # 56\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = DoubleConv(32, 64) # 28\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        # self.conv3 = DoubleConv(64, 128) # 14\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        # self.conv4 = DoubleConv(128, 256) # 7\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "\n",
        "        # self.pool4 = nn.MaxPool3d(2)\n",
        "        # self.conv5 = DoubleConv(256, 512)\n",
        "\n",
        "        self.fc1 = nn.Linear(256*7*7, 256)\n",
        "        self.fc2 = nn.Linear(256, cls)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.dropout0 = nn.Dropout(0.25)\n",
        "        # self.dropout1 = nn.Dropout(0.5)\n",
        "    def forward(self, x):\n",
        "        c0 = self.conv0(x)     \n",
        "        p0 = F.relu(self.pool0(c0))\n",
        "        # print(p0.shape)\n",
        "        c1 = self.conv1(p0)\n",
        "        p1 = self.pool1(c1)\n",
        "        # p1 = self.dropout0(p1)\n",
        "        c2 = self.conv2(p1)\n",
        "        p2 = self.pool2(c2)\n",
        "        p2 = self.dropout(p2)\n",
        "        c3 = self.conv3(p2)\n",
        "        p3 = F.relu(self.pool3(c3))\n",
        "        p3 = self.dropout(p3)\n",
        "        c4 = F.relu(self.conv4(p3))\n",
        "        out = c4.view(-1, 256*7*7)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        # out = nn.LogSoftmax(dim = 1)(x)\n",
        "        return out\n",
        "\n",
        "model = CNN()\n",
        "model.cuda()\n",
        "model.train()\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(3,224,224))\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVj0pU-wnNxh"
      },
      "source": [
        "## grating stims\n",
        "# read pickle file\n",
        "with open('Customized_Gratings/Small_Gratings.pkl','rb') as f:\n",
        "  gratings = pickle.load(f)\n",
        "G_train, G_test = train_test_split(gratings,test_size = 0.1, shuffle = True, random_state = 1)\n",
        "cls = 9\n",
        "times = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I10oFXKQJ8FF"
      },
      "source": [
        "## Non-random grating generator\n",
        "\n",
        "cls = 9\n",
        "times = 10\n",
        "#train index\n",
        "num = len(gratings)\n",
        "div = 180/cls\n",
        "index_tmp = np.repeat(np.arange(num),cls*cls)\n",
        "k = []\n",
        "for i in range(cls):\n",
        "  k.extend([i*div])\n",
        "k = k*num*cls\n",
        "l = []\n",
        "for i in range(cls):\n",
        "  l.extend([i*div])\n",
        "l = l*num\n",
        "l = np.repeat(l,cls)\n",
        "data_index = [i for i in zip(index_tmp,k,l)] \n",
        "## grating based on requirements specified in index\n",
        "\n",
        "class myDataset():\n",
        "    \"\"\"\n",
        "    Args:\n",
        "              input input_file_list = [f_content, f_angle]\n",
        "              target_file_list = f_trans      \n",
        "              patch_size: int , the cubic patch parameter     \n",
        "    \"\"\"\n",
        "    def __init__(self,input_patches,index,cls = cls, input_size=224,random = False):\n",
        "\n",
        "        self.index = index\n",
        "        self.inputs = input_patches\n",
        "        self.input_size = input_size\n",
        "        self.div = 180/cls\n",
        "       \n",
        "    def __len__(self):\n",
        "        return len(self.index)\n",
        "\n",
        "    @staticmethod\n",
        "    def rotate(img,angle):\n",
        "        return imutils.rotate(img, angle=angle)\n",
        "\n",
        "    @staticmethod\n",
        "    ##Randomly distributed with minimum distance\n",
        "    def random_distributed_with_minimum(n_points,half_distance,boundary_length):\n",
        "      position = []\n",
        "      occupied_length = 0\n",
        "      remain_length = boundary_length \n",
        "      def set_first_remain_point(remain_n,remain_length):\n",
        "          return random.randint(half_distance, remain_length - remain_n * half_distance *2 - half_distance) + occupied_length\n",
        "      for i in range(n_points,0,-1):\n",
        "          remain_n = i - 1\n",
        "          p = set_first_remain_point(remain_n,remain_length)\n",
        "          occupied_length = p + half_distance\n",
        "          remain_length = boundary_length - occupied_length\n",
        "          position.append(p)\n",
        "      sign = random.randint(0,1)\n",
        "      if sign:\n",
        "        position =[(boundary_length - i) for i in position]\n",
        "      return position\n",
        "    def __getitem__(self, item):\n",
        "        global p,img_0,n,img0,a\n",
        "        idx, angle_l, angle_g = self.index[item]  \n",
        "        if item == 0 or self.index[item-1][0] != self.index[item][0]:\n",
        "            img_0 = self.inputs[idx]\n",
        "            #uniform with random shading\n",
        "            img_0 = img_0/255*random.uniform(0.5,1)\n",
        "            a = img_0.shape[1]  #half of the patch's side length\n",
        "            #num of gratings & generate random distributed positions\n",
        "            n = 2 if self.input_size//a == 2 else random.randint(2,self.input_size//a)\n",
        "            p = self.random_distributed_with_minimum(n,np.int(a//2),self.input_size)\n",
        "            #Initialize with Gaussian noise\n",
        "            noise_sigma = random.uniform(0,0.3)\n",
        "            img0 = np.random.randn(3,self.input_size,self.input_size) * noise_sigma\n",
        "        \n",
        "        #random rotate locally \n",
        "        img = self.rotate(img_0.swapaxes(0,2),angle_l-angle_g).swapaxes(0,2)\n",
        "\n",
        "        img_1 = np.zeros((3,self.input_size,self.input_size))\n",
        "        img_out = img0.copy()\n",
        "        #merge based on random distributed positions\n",
        "        for i in p:\n",
        "          # print(int(a//2),i,'\\n')\n",
        "          img_1[:,int(self.input_size//2-a//2):int(self.input_size//2+a//2),i-int(a//2):i+int(a//2)] += img\n",
        "\n",
        "        #rotate globally based on label difference\n",
        "        img_1 = self.rotate(img_1.swapaxes(0,2),angle_g).swapaxes(0,2)\n",
        "        img_out += img_1\n",
        "        img_out =  (img_out-np.min(img_out))/(np.max(img_out)-np.min(img_out))\n",
        "        label_l = np.int(angle_l//self.div)\n",
        "        label_g = np.int(angle_g//self.div)\n",
        "\n",
        "        return torch.from_numpy(img_out).float(), label_l,label_g\n",
        "batch_size = 275\n",
        "dataset = myDataset(gratings,data_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8dpASVRJ8q9"
      },
      "source": [
        "Local Orientation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtGkVJrLKbh3"
      },
      "source": [
        "model_name = 'model_CNN_local_muilti_angle'\n",
        "model.load_state_dict(torch.load(\"CNN_model/\"+model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTOmVW4AK6ii"
      },
      "source": [
        "##save all convolutional layers\n",
        " \n",
        "model_weights = [] # we will save the conv layer weights in this list\n",
        "conv_layers = [] # we will save the 49 conv layers in this list\n",
        "model_children = list(model.children())\n",
        "# counter to keep count of the conv layers\n",
        "counter = 0 \n",
        "# append all the conv layers and their respective weights to the list\n",
        "for i in range(len(model_children)):\n",
        "    if (type(model_children[i]) == nn.Conv2d) :\n",
        "        counter += 1\n",
        "        model_weights.append(model_children[i].weight)\n",
        "        conv_layers.append(model_children[i])\n",
        "    elif type(model_children[i]) == DoubleConv:\n",
        "          for child in model_children[i].conv.children():\n",
        "                if type(child) == nn.Conv2d:\n",
        "                    counter += 1\n",
        "                    model_weights.append(child.weight)\n",
        "                    conv_layers.append(child)\n",
        " \n",
        "print(f\"Total convolutional layers: {counter}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftwTGOESLESB"
      },
      "source": [
        "# take a look at the conv layers and the respective weights\n",
        "for weight, conv in zip(model_weights, conv_layers):\n",
        "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
        "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")\n",
        "# visualize the first conv layer filters\n",
        "plt.figure(figsize=(20, 17))\n",
        "for i, filter in enumerate(model_weights[0]):\n",
        "    plt.subplot(8, 8, i+1) # (8, 8) because in conv0 we have 7x7 filters and total of 64 (see printed shapes)\n",
        "    plt.imshow(filter[0, :, :].cpu().detach(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    # plt.savefig('../outputs/filter.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyqM0a9pLebJ"
      },
      "source": [
        "class SaveFeatures():\n",
        "    \"\"\"注册hook和移除hook\n",
        "    \"\"\"\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        # self.features = output.clone().detach().requires_grad_(True)\n",
        "        self.features = output.clone()\n",
        "    def close(self):\n",
        "        self.hook.remove()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4Eh_8KWg1nP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EucJ_8awLI7o"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 生成随机的图片\n",
        "sz = 224\n",
        "# 超参数\n",
        "lr = 0.1 # 学习率\n",
        "opt_steps = 5 # 迭代次数\n",
        "upscaling_steps = 1 # 图像放大次数\n",
        "# blur=3\n",
        "# upscaling_factor=1.2 # 把图像变粗\n",
        "for layer in range(5,len(conv_layers)):\n",
        "  for filter in range(10000):\n",
        "# 定义处理时的均值与方差\n",
        "# img = np.uint8(np.random.uniform(150, 180, (3, sz, sz)))/255\n",
        "    img = np.uint8(np.random.randn(3, sz, sz))\n",
        "    img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "    # img[None]可以增加一个维度\n",
        "    img = torch.from_numpy(img[None]).float().to(device)\n",
        "    activations = SaveFeatures(conv_layers[layer])\n",
        "    # activations = SaveFeatures(list(model.children())[2].conv[4])\n",
        "    for epoch in range(upscaling_steps):  # scale the image up upscaling_steps times\n",
        "        # --------------------------------------------------------------------------------\n",
        "        # 因为原始的网络对图片做了normalization, 所以这里对输入图片也要做normalization\n",
        "        # --------------------------------------------------------------------------------\n",
        "        # img = (img - cnn_normalization_mean) / cnn_normalization_std     \n",
        "        # print('Imgshape1 : ',img.shape)\n",
        "        img_var = Variable(img, requires_grad=True)  # convert image to Variable that requires grad\n",
        "        # ----------\n",
        "        # 定义优化器\n",
        "        # ----------\n",
        "        optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "        for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "            optimizer.zero_grad()\n",
        "            model(img_var) # 正向传播\n",
        "            if (filter == 0) and  (n == 0):\n",
        "                max_fil = activations.features.shape[1]\n",
        "                print('maximum filter', max_fil)\n",
        "               \n",
        "            loss = -F.relu(activations.features)[0, filter].mean() # loss相当于最大该层的激活的值\n",
        "            loss.backward()\n",
        "            # print(loss)\n",
        "            optimizer.step()\n",
        "        # ------------\n",
        "        # 图像进行还原\n",
        "        # ------------\n",
        "        # print('Loss:',loss.cpu().detach().numpy())\n",
        "        # img = img_var * cnn_normalization_std + cnn_normalization_mean # 这个使用img_var变换img\n",
        " \n",
        "        img = img_var.data.cpu().numpy()[0].transpose(1,2,0)\n",
        "        img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "        # sz = int(upscaling_factor * sz)  # calculate new image size\n",
        "        # img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
        "        # if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
        "        # print('Imgshape : ',img.shape)\n",
        "        img = torch.from_numpy(img.transpose(2,0,1)[None]).to(device)\n",
        "        # print('Imgshape3 : ',img.shape)\n",
        "        # print(str(epoch),',Finished')\n",
        "        # print('=======')\n",
        "    activations.close() # 移除hook\n",
        "    #最后将图像进行保存即可。\n",
        " \n",
        "    # 保存图片\n",
        "    image = img.cpu().clone()\n",
        "    image = image.squeeze(0)\n",
        "    unloader = transforms.ToPILImage()\n",
        "    image = unloader(image)\n",
        "    image = cv2.cvtColor(np.asarray(image),cv2.COLOR_RGB2BGR)\n",
        "    # image = cv2.resize(image, (56,56), interpolation = cv2.INTER_CUBIC)\n",
        "    if filter%16 == 0:\n",
        "        print('=======================Conv_layer%d_part%d========================='%(layer,filter//16))\n",
        "        fig = plt.figure(figsize = (32 ,8))\n",
        "        ax = fig.subplots(2,8)\n",
        "        plt.suptitle('Conv_layer%d_part%d'%(layer,filter//16),y = 1)\n",
        "    ax[filter%16//8,filter%8].imshow(image)\n",
        "    ax[filter%16//8,filter%8].axis('off')\n",
        "    if filter%16 == 15:\n",
        "      plt.savefig('filters/%s_opt%dsteps_Conv_layer%d_part%d'%(model_name,opt_steps,layer,filter//16), dpi=300)\n",
        "      plt.tight_layout() \n",
        "      plt.show()\n",
        "      plt.close()\n",
        "      \n",
        "    # cv2.imwrite('res1.jpg',image)\n",
        "    torch.cuda.empty_cache()\n",
        "    if filter+1 == max_fil:\n",
        "      # print('Loss:',loss.cpu().detach().numpy())\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77JQRHMpLXvP"
      },
      "source": [
        "##find the filters with max activation \n",
        "img = []\n",
        "img1 = []\n",
        "idx = 81\n",
        "for i in range(cls):\n",
        "  id = i*9 + idx\n",
        "  data, l, g = dataset[id]\n",
        "  data.unsqueeze_(0)\n",
        "  data = data.cuda()\n",
        "  img.append(data)\n",
        "  # ax[i].imshow(data[0,].cpu().numpy().swapaxes(0,2).swapaxes(0,1))\n",
        "  # ax[i].axis('off')\n",
        "  if i == 2:\n",
        "    img1.append(data)\n",
        "    for j in range(1,cls):\n",
        "      id = i*9 + idx + j\n",
        "      data, l, g = dataset[id]\n",
        "      data.unsqueeze_(0)\n",
        "      data = data.cuda()\n",
        "      img1.append(data)\n",
        "\n",
        "input_img = img1\n",
        "\n",
        "print('input images')\n",
        "fig = plt.figure(figsize = (5*cls,5))\n",
        "ax = fig.subplots(1,cls)\n",
        "for i, data in enumerate(input_img):\n",
        "  ax[i].imshow(data[0,].cpu().numpy().swapaxes(0,2).swapaxes(0,1))\n",
        "  ax[i].axis('off')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "for i in range(len(conv_layers)):\n",
        "  fig = plt.figure(figsize = (8,25))\n",
        "  plt.title('conv_layer{}'.format(i))\n",
        "  for j, data in enumerate(input_img):\n",
        "    activations = SaveFeatures(conv_layers[i])\n",
        "    output = model(data)\n",
        "    max_fil = activations.features[0,].cpu().detach().numpy().shape[0]\n",
        "    avg_act = np.mean(F.relu(activations.features)[0,].cpu().detach().numpy().reshape(max_fil,-1),axis = 1).copy()\n",
        "    activations.close() # 移除hook\n",
        "    torch.cuda.empty_cache()\n",
        "    plt.subplot(9,1,j+1)\n",
        "    \n",
        "    plt.text(0.64*max_fil,0.95*np.max(avg_act),'Max 5 activations:{}'.format(np.argsort(avg_act)[::-1][:5]))\n",
        "    plt.bar(np.arange(max_fil),avg_act,0.9)\n",
        "  plt.tight_layout() \n",
        "  plt.show()\n",
        "  plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anvtolmidUyG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHMCDm6Jdy3S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdp1ZCzzjArx"
      },
      "source": [
        "##Find the filter with max activation in each orientation\n",
        "\n",
        "# Filter visualization function\n",
        "def filter_vis(layer,filter,conv_layers = conv_layers,opt_steps = 20,lr = 0.1,sz = 224):\n",
        "  ##Function for filter visualization\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  img = np.uint8(np.random.randn(3, sz, sz))\n",
        "  img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "\n",
        "  img = torch.from_numpy(img[None]).float().to(device)\n",
        "  activations = SaveFeatures(conv_layers[layer])\n",
        "  img_var = Variable(img, requires_grad=True)  # convert image to Variable that requires grad\n",
        "\n",
        "  optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "  for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "      optimizer.zero_grad()\n",
        "      model(img_var) # 正向传播\n",
        "      if (filter == 0) and  (n == 0):\n",
        "          max_fil = activations.features.shape[1]\n",
        "          print('maximum filter', max_fil)\n",
        "          \n",
        "      loss = -F.relu(activations.features)[0, filter].mean() # loss相当于最大该层的激活的值\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  print('Loss:',loss.cpu().detach().numpy())\n",
        "  img = img_var.data.cpu().numpy()[0].transpose(1,2,0)\n",
        "  img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "  img = torch.from_numpy(img.transpose(2,0,1)[None]).to(device)\n",
        "\n",
        "  activations.close() # 移除hook\n",
        "  #最后将图像进行保存即可。\n",
        "\n",
        "  # 保存图片\n",
        "  image = img.cpu().clone()\n",
        "  image = image.squeeze(0)\n",
        "  unloader = transforms.ToPILImage()\n",
        "  image = unloader(image)\n",
        "  image = cv2.cvtColor(np.asarray(image),cv2.COLOR_RGB2BGR)\n",
        "  plt.imshow(image)\n",
        "  plt.savefig('filters/%s_opt%dsteps_Conv_layer%d_filter%d'%(model_name,opt_steps,layer,filter), dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "##find the filters with max activation \n",
        "df = pd.DataFrame(columns=['id','local','global'] + ['layer%d'%i for i in range(7)])\n",
        "idx = 81\n",
        "for i in range(cls*cls*100):\n",
        "  id = i +idx\n",
        "  data, l, g = dataset[id]\n",
        "  data.unsqueeze_(0)\n",
        "  data = data.cuda()\n",
        "  max = [id,l,g]\n",
        "  for j in range(len(conv_layers)):\n",
        "      activations = SaveFeatures(conv_layers[j])\n",
        "      output = model(data)\n",
        "      max_fil = activations.features[0,].cpu().detach().numpy().shape[0]\n",
        "      avg_act = np.mean(F.relu(activations.features)[0,].cpu().detach().numpy().reshape(max_fil,-1),axis = 1).copy()\n",
        "      # if i == 0 and np.argmax(avg_act) != 12:\n",
        "      #   plt.imshow(data[0,].cpu().numpy().swapaxes(0,2).swapaxes(0,1))\n",
        "      #   plt.show()\n",
        "      #   plt.close()\n",
        "      max.append(np.argmax(avg_act))\n",
        "      activations.close() # 移除hook\n",
        "      torch.cuda.empty_cache()\n",
        "  df.loc[i] = max\n",
        "display(df)\n",
        "\n",
        "for layer in range(7):\n",
        "  for filter in df[df['local'] == 2]['layer%d'%layer].unique():\n",
        "      print('### layer%d filter%d'%(layer,filter))\n",
        "      print(df[df['layer%d'%layer] == filter]['local'].value_counts())\n",
        "      print(df[df['layer%d'%layer] == filter]['global'].value_counts())\n",
        "      filter_vis(layer,filter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s59vH9gFJ5d7"
      },
      "source": [
        "Global Orientation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGx_3MvbXWkb"
      },
      "source": [
        "model_name = 'model_CNN_global_9angles'\n",
        "model.load_state_dict(torch.load(\"CNN_model/\"+model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8BGD6gzLn14"
      },
      "source": [
        "##save all convolutional layers\n",
        " \n",
        "model_weights = [] # we will save the conv layer weights in this list\n",
        "conv_layers = [] # we will save the 49 conv layers in this list\n",
        "model_children = list(model.children())\n",
        "# counter to keep count of the conv layers\n",
        "counter = 0 \n",
        "# append all the conv layers and their respective weights to the list\n",
        "for i in range(len(model_children)):\n",
        "    if (type(model_children[i]) == nn.Conv2d) :\n",
        "        counter += 1\n",
        "        model_weights.append(model_children[i].weight)\n",
        "        conv_layers.append(model_children[i])\n",
        "    elif type(model_children[i]) == DoubleConv:\n",
        "          for child in model_children[i].conv.children():\n",
        "                if type(child) == nn.Conv2d:\n",
        "                    counter += 1\n",
        "                    model_weights.append(child.weight)\n",
        "                    conv_layers.append(child)\n",
        " \n",
        "print(f\"Total convolutional layers: {counter}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVFQsqHYLn15"
      },
      "source": [
        "# take a look at the conv layers and the respective weights\n",
        "for weight, conv in zip(model_weights, conv_layers):\n",
        "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
        "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")\n",
        "# visualize the first conv layer filters\n",
        "plt.figure(figsize=(20, 17))\n",
        "for i, filter in enumerate(model_weights[0]):\n",
        "    plt.subplot(8, 8, i+1) # (8, 8) because in conv0 we have 7x7 filters and total of 64 (see printed shapes)\n",
        "    plt.imshow(filter[0, :, :].cpu().detach(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    # plt.savefig('../outputs/filter.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJSZJp0ZLn15"
      },
      "source": [
        "class SaveFeatures():\n",
        "    \"\"\"注册hook和移除hook\n",
        "    \"\"\"\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        # self.features = output.clone().detach().requires_grad_(True)\n",
        "        self.features = output.clone()\n",
        "    def close(self):\n",
        "        self.hook.remove()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bicTbeRULn15"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 生成随机的图片\n",
        "sz = 224\n",
        "# 超参数\n",
        "lr = 0.1 # 学习率\n",
        "opt_steps = 25 # 迭代次数\n",
        "upscaling_steps = 1 # 图像放大次数\n",
        "# blur=3\n",
        "# upscaling_factor=1.2 # 把图像变粗\n",
        "for layer in range(len(conv_layers)):\n",
        "  for filter in range(10000):\n",
        "# 定义处理时的均值与方差\n",
        "# img = np.uint8(np.random.uniform(150, 180, (3, sz, sz)))/255\n",
        "    img = np.uint8(np.random.randn(3, sz, sz))\n",
        "    img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "    # img[None]可以增加一个维度\n",
        "    img = torch.from_numpy(img[None]).float().to(device)\n",
        "    activations = SaveFeatures(conv_layers[layer])\n",
        "    # activations = SaveFeatures(list(model.children())[2].conv[4])\n",
        "    for epoch in range(upscaling_steps):  # scale the image up upscaling_steps times\n",
        "        # --------------------------------------------------------------------------------\n",
        "        # 因为原始的网络对图片做了normalization, 所以这里对输入图片也要做normalization\n",
        "        # --------------------------------------------------------------------------------\n",
        "        # img = (img - cnn_normalization_mean) / cnn_normalization_std     \n",
        "        # print('Imgshape1 : ',img.shape)\n",
        "        img_var = Variable(img, requires_grad=True)  # convert image to Variable that requires grad\n",
        "        # ----------\n",
        "        # 定义优化器\n",
        "        # ----------\n",
        "        optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "        for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "            optimizer.zero_grad()\n",
        "            model(img_var) # 正向传播\n",
        "            if (filter == 0) and  (n == 0):\n",
        "                max_fil = activations.features.shape[1]\n",
        "                print('maximum filter', max_fil)\n",
        "               \n",
        "            loss = -F.relu(activations.features)[0, filter].mean() # loss相当于最大该层的激活的值\n",
        "            loss.backward()\n",
        "            # print(loss)\n",
        "            optimizer.step()\n",
        "        # ------------\n",
        "        # 图像进行还原\n",
        "        # ------------\n",
        "        # print('Loss:',loss.cpu().detach().numpy())\n",
        "        # img = img_var * cnn_normalization_std + cnn_normalization_mean # 这个使用img_var变换img\n",
        " \n",
        "        img = img_var.data.cpu().numpy()[0].transpose(1,2,0)\n",
        "        img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "        # sz = int(upscaling_factor * sz)  # calculate new image size\n",
        "        # img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
        "        # if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
        "        # print('Imgshape : ',img.shape)\n",
        "        img = torch.from_numpy(img.transpose(2,0,1)[None]).to(device)\n",
        "        # print('Imgshape3 : ',img.shape)\n",
        "        # print(str(epoch),',Finished')\n",
        "        # print('=======')\n",
        "    activations.close() # 移除hook\n",
        "    #最后将图像进行保存即可。\n",
        " \n",
        "    # 保存图片\n",
        "    image = img.cpu().clone()\n",
        "    image = image.squeeze(0)\n",
        "    unloader = transforms.ToPILImage()\n",
        "    image = unloader(image)\n",
        "    image = cv2.cvtColor(np.asarray(image),cv2.COLOR_RGB2BGR)\n",
        "    # image = cv2.resize(image, (56,56), interpolation = cv2.INTER_CUBIC)\n",
        "    if filter%16 == 0:\n",
        "        print('=======================Conv_layer%d_part%d========================='%(layer,filter//16))\n",
        "        fig = plt.figure(figsize = (32 ,8))\n",
        "        ax = fig.subplots(2,8)\n",
        "        plt.suptitle('Conv_layer%d_part%d'%(layer,filter//16),y = 1)\n",
        "    ax[filter%16//8,filter%8].imshow(image)\n",
        "    ax[filter%16//8,filter%8].axis('off')\n",
        "    if filter%16 == 15:\n",
        "      plt.savefig('filters/%s_opt%dsteps_Conv_layer%d_part%d'%(model_name,opt_steps,layer,filter//16), dpi=300)\n",
        "      plt.tight_layout() \n",
        "      plt.show()\n",
        "      plt.close()\n",
        "      \n",
        "    # cv2.imwrite('res1.jpg',image)\n",
        "    torch.cuda.empty_cache()\n",
        "    if filter+1 == max_fil:\n",
        "      # print('Loss:',loss.cpu().detach().numpy())\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUnAr9FZMBIL"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# 生成随机的图片\n",
        "sz = 224\n",
        "# 超参数\n",
        "lr = 0.1 # 学习率\n",
        "opt_steps = 50 # 迭代次数\n",
        "upscaling_steps = 1 # 图像放大次数\n",
        "# blur=3\n",
        "# upscaling_factor=1.2 # 把图像变粗\n",
        "for layer in range(len(conv_layers)):\n",
        "  for filter in range(10000):\n",
        "# 定义处理时的均值与方差\n",
        "# img = np.uint8(np.random.uniform(150, 180, (3, sz, sz)))/255\n",
        "    img = np.uint8(np.random.randn(3, sz, sz))\n",
        "    img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "    # img[None]可以增加一个维度\n",
        "    img = torch.from_numpy(img[None]).float().to(device)\n",
        "    activations = SaveFeatures(conv_layers[layer])\n",
        "    # activations = SaveFeatures(list(model.children())[2].conv[4])\n",
        "    for epoch in range(upscaling_steps):  # scale the image up upscaling_steps times\n",
        "        # --------------------------------------------------------------------------------\n",
        "        # 因为原始的网络对图片做了normalization, 所以这里对输入图片也要做normalization\n",
        "        # --------------------------------------------------------------------------------\n",
        "        # img = (img - cnn_normalization_mean) / cnn_normalization_std     \n",
        "        # print('Imgshape1 : ',img.shape)\n",
        "        img_var = Variable(img, requires_grad=True)  # convert image to Variable that requires grad\n",
        "        # ----------\n",
        "        # 定义优化器\n",
        "        # ----------\n",
        "        optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "        for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "            optimizer.zero_grad()\n",
        "            model(img_var) # 正向传播\n",
        "            if (filter == 0) and  (n == 0):\n",
        "                max_fil = activations.features.shape[1]\n",
        "                print('maximum filter', max_fil)\n",
        "               \n",
        "            loss = -F.relu(activations.features)[0, filter].mean() # loss相当于最大该层的激活的值\n",
        "            loss.backward()\n",
        "            # print(loss)\n",
        "            optimizer.step()\n",
        "        # ------------\n",
        "        # 图像进行还原\n",
        "        # ------------\n",
        "        # print('Loss:',loss.cpu().detach().numpy())\n",
        "        # img = img_var * cnn_normalization_std + cnn_normalization_mean # 这个使用img_var变换img\n",
        " \n",
        "        img = img_var.data.cpu().numpy()[0].transpose(1,2,0)\n",
        "        img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "        # sz = int(upscaling_factor * sz)  # calculate new image size\n",
        "        # img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
        "        # if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
        "        # print('Imgshape : ',img.shape)\n",
        "        img = torch.from_numpy(img.transpose(2,0,1)[None]).to(device)\n",
        "        # print('Imgshape3 : ',img.shape)\n",
        "        # print(str(epoch),',Finished')\n",
        "        # print('=======')\n",
        "    activations.close() # 移除hook\n",
        "    #最后将图像进行保存即可。\n",
        " \n",
        "    # 保存图片\n",
        "    image = img.cpu().clone()\n",
        "    image = image.squeeze(0)\n",
        "    unloader = transforms.ToPILImage()\n",
        "    image = unloader(image)\n",
        "    image = cv2.cvtColor(np.asarray(image),cv2.COLOR_RGB2BGR)\n",
        "    # image = cv2.resize(image, (56,56), interpolation = cv2.INTER_CUBIC)\n",
        "    if filter%16 == 0:\n",
        "        print('=======================Conv_layer%d_part%d========================='%(layer,filter//16))\n",
        "        fig = plt.figure(figsize = (32 ,8))\n",
        "        ax = fig.subplots(2,8)\n",
        "        plt.suptitle('Conv_layer%d_part%d'%(layer,filter//16),y = 1)\n",
        "    ax[filter%16//8,filter%8].imshow(image)\n",
        "    ax[filter%16//8,filter%8].axis('off')\n",
        "    if filter%16 == 15:\n",
        "      plt.savefig('filters/%s_opt%dsteps_Conv_layer%d_part%d'%(model_name,opt_steps,layer,filter//16), dpi=300)\n",
        "      plt.tight_layout() \n",
        "      plt.show()\n",
        "      plt.close()\n",
        "      \n",
        "    # cv2.imwrite('res1.jpg',image)\n",
        "    torch.cuda.empty_cache()\n",
        "    if filter+1 == max_fil:\n",
        "      # print('Loss:',loss.cpu().detach().numpy())\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqvy7V5YLn16"
      },
      "source": [
        "##find the filters with max activation \n",
        "img = []\n",
        "img1 = []\n",
        "idx = 810\n",
        "for i in range(cls):\n",
        "  id = i*9 + idx\n",
        "  data, l, g = dataset[id]\n",
        "  data.unsqueeze_(0)\n",
        "  data = data.cuda()\n",
        "  img.append(data)\n",
        "  # ax[i].imshow(data[0,].cpu().numpy().swapaxes(0,2).swapaxes(0,1))\n",
        "  # ax[i].axis('off')\n",
        "  if i == 2:\n",
        "    img1.append(data)\n",
        "    for j in range(1,cls):\n",
        "      id = i*9 + idx + j\n",
        "      data, l, g = dataset[id]\n",
        "      data.unsqueeze_(0)\n",
        "      data = data.cuda()\n",
        "      img1.append(data)\n",
        "\n",
        "input_img = img\n",
        "\n",
        "print('input images')\n",
        "fig = plt.figure(figsize = (5*cls,5))\n",
        "ax = fig.subplots(1,cls)\n",
        "for i, data in enumerate(input_img):\n",
        "  ax[i].imshow(data[0,].cpu().numpy().swapaxes(0,2).swapaxes(0,1))\n",
        "  ax[i].axis('off')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "for i in range(len(conv_layers)):\n",
        "  fig = plt.figure(figsize = (8,25))\n",
        "  plt.title('conv_layer{}'.format(i))\n",
        "  for j, data in enumerate(input_img):\n",
        "    activations = SaveFeatures(conv_layers[i])\n",
        "    output = model(data)\n",
        "    max_fil = activations.features[0,].cpu().detach().numpy().shape[0]\n",
        "    avg_act = np.mean(F.relu(activations.features)[0,].cpu().detach().numpy().reshape(max_fil,-1),axis = 1).copy()\n",
        "    activations.close() # 移除hook\n",
        "    torch.cuda.empty_cache()\n",
        "    plt.subplot(9,1,j+1)\n",
        "    \n",
        "    plt.text(0.64*max_fil,0.95*np.max(avg_act),'Max 5 activations:{}'.format(np.argsort(avg_act)[::-1][:5]))\n",
        "    plt.bar(np.arange(max_fil),avg_act,0.9)\n",
        "  plt.tight_layout() \n",
        "  plt.show()\n",
        "  plt.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYhRmiJBLwnR"
      },
      "source": [
        "##Find the filter with max activation in each orientation\n",
        "\n",
        "# Filter visualization function\n",
        "def filter_vis(layer,filter,conv_layers = conv_layers,opt_steps = 30,lr = 0.1,sz = 224):\n",
        "  ##Function for filter visualization\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  img = np.uint8(np.random.randn(3, sz, sz))\n",
        "  img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "\n",
        "  img = torch.from_numpy(img[None]).float().to(device)\n",
        "  activations = SaveFeatures(conv_layers[layer])\n",
        "  img_var = Variable(img, requires_grad=True)  # convert image to Variable that requires grad\n",
        "\n",
        "  optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "  for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
        "      optimizer.zero_grad()\n",
        "      model(img_var) # 正向传播\n",
        "      if (filter == 0) and  (n == 0):\n",
        "          max_fil = activations.features.shape[1]\n",
        "          print('maximum filter', max_fil)\n",
        "          \n",
        "      loss = -F.relu(activations.features)[0, filter].mean() # loss相当于最大该层的激活的值\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  print('Loss:',loss.cpu().detach().numpy())\n",
        "  img = img_var.data.cpu().numpy()[0].transpose(1,2,0)\n",
        "  img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
        "  img = torch.from_numpy(img.transpose(2,0,1)[None]).to(device)\n",
        "\n",
        "  activations.close() # 移除hook\n",
        "  #最后将图像进行保存即可。\n",
        "\n",
        "  # 保存图片\n",
        "  image = img.cpu().clone()\n",
        "  image = image.squeeze(0)\n",
        "  unloader = transforms.ToPILImage()\n",
        "  image = unloader(image)\n",
        "  image = cv2.cvtColor(np.asarray(image),cv2.COLOR_RGB2BGR)\n",
        "  plt.imshow(image)\n",
        "  plt.savefig('filters/%s_opt%dsteps_Conv_layer%d_filter%d'%(model_name,opt_steps,layer,filter), dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "##find the filters with max activation \n",
        "df = pd.DataFrame(columns=['id','local','global'] + ['layer%d'%i for i in range(7)])\n",
        "idx = 81\n",
        "for i in range(cls*cls*100):\n",
        "  id = i +idx\n",
        "  data, l, g = dataset[id]\n",
        "  data.unsqueeze_(0)\n",
        "  data = data.cuda()\n",
        "  max = [id,l,g]\n",
        "  for j in range(len(conv_layers)):\n",
        "      activations = SaveFeatures(conv_layers[j])\n",
        "      output = model(data)\n",
        "      max_fil = activations.features[0,].cpu().detach().numpy().shape[0]\n",
        "      avg_act = np.mean(F.relu(activations.features)[0,].cpu().detach().numpy().reshape(max_fil,-1),axis = 1).copy()\n",
        "      # if i == 0 and np.argmax(avg_act) != 12:\n",
        "      #   plt.imshow(data[0,].cpu().numpy().swapaxes(0,2).swapaxes(0,1))\n",
        "      #   plt.show()\n",
        "      #   plt.close()\n",
        "      max.append(np.argmax(avg_act))\n",
        "      activations.close() # 移除hook\n",
        "      torch.cuda.empty_cache()\n",
        "  df.loc[i] = max\n",
        "display(df)\n",
        "\n",
        "for layer in range(7):\n",
        "  for filter in df[df['local'] == 2]['layer%d'%layer].unique():\n",
        "      print('### layer%d filter%d'%(layer,filter))\n",
        "      print(df[df['layer%d'%layer] == filter]['local'].value_counts())\n",
        "      print(df[df['layer%d'%layer] == filter]['global'].value_counts())\n",
        "      filter_vis(layer,filter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HG8y9T63Sar"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}